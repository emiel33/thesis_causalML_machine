Index: Clairvoyance crn/MM.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># Necessary packages\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport numpy as np\r\nimport warnings\r\nwarnings.filterwarnings('ignore')\r\n\r\nimport sys, os\r\nsys.path.append(os.path.realpath('..'))\r\n\r\n\r\n#from utils import PipelineComposer\r\n\r\nimport logging\r\nlogger = logging.getLogger()\r\nlogger.setLevel(logging.INFO)\r\n\r\n\r\n# write alll print output to program output file\r\nfile_path = 'program output.txt'\r\nsys.stdout = open(file_path, \"w\")\r\n\r\n# IN THE NEXT PART LOAD THE DATA SET AND FORMAT IT AS NEEDED\r\n\r\nfrom datasets.data_loader import CSVLoader\r\n\r\n# Define data name\r\ndata_name = 'machine_1'\r\n# Define data dictionary\r\ndata_directory = data_name + '/' + data_name + '_'\r\n\r\n# Load train and test datasets\r\ndata_loader_training = CSVLoader(static_file=data_directory + 'static_train_data.csv.gz',\r\n                                 temporal_file=data_directory + 'temporal_train_data_eav.csv.gz')\r\n\r\ndata_loader_testing = CSVLoader(static_file=data_directory + 'static_test_data.csv.gz',\r\n                                temporal_file=data_directory + 'temporal_test_data_eav.csv.gz')\r\n\r\ndataset_training = data_loader_training.load()\r\ndataset_testing = data_loader_testing.load()\r\n\r\nprint('Finish data loading.')\r\n\r\n\r\n\r\n\r\n\r\n\r\n#DEFINE PROBLEM\r\nfrom preprocessing.encoding import ProblemMaker\r\n# Define parameters\r\nproblem = 'online'\r\nmax_seq_len = 20\r\nlabel_name = ' productionvolume' #label name of production capacity, colum that will be tracked\r\ntreatment = [' treatment']#label name of the repair/maintenance\r\nwindow = 1\r\n\r\n# Define problem \r\nproblem_maker = ProblemMaker(problem=problem, label=[label_name],\r\n                             max_seq_len=max_seq_len, treatment=treatment, window=window)\r\n\r\ndataset_training = problem_maker.fit_transform(dataset_training)\r\ndataset_testing = problem_maker.fit_transform(dataset_testing)\r\n\r\n# Set other parameters\r\nmetric_name = 'mse' #optimize the Area Under Curve\r\ntask = 'classification' # treatment either happens or not so classification\r\n\r\nmetric_sets = [metric_name]\r\nmetric_parameters =  {'problem': problem, 'label_name': [label_name]}\r\n\r\nprint('Finish defining problem.')\r\n\r\n\r\n \r\n \r\n# LEARN AND PREDICT\r\nfrom treatments.treatments import treatment_effects_model\r\n\r\n# Set the treatment effects model\r\nmodel_name = 'CRN'\r\nprojection_horizon = 5\r\n\r\n# Set up validation for early stopping and best model saving\r\ndataset_training.train_val_test_split(prob_val=0.2, prob_test = 0.0)\r\n\r\n\r\nmodel_parameters={'encoder_rnn_hidden_units': 16,\r\n                  'encoder_br_size': 8,\r\n                  'encoder_fc_hidden_units':16,\r\n                  'encoder_learning_rate': 0.001,\r\n                  'encoder_batch_size': 32,\r\n                  'encoder_keep_prob': 0.9,\r\n                  'encoder_num_epochs': 100,\r\n                  'encoder_max_alpha': 1.0,\r\n                  'decoder_br_size': 8,\r\n                  'decoder_fc_hidden_units': 16,\r\n                  'decoder_learning_rate': 0.001,\r\n                  'decoder_batch_size': 64,\r\n                  'decoder_keep_prob': 0.9,\r\n                  'decoder_num_epochs': 10,\r\n                  'decoder_max_alpha': 1.0,\r\n                  'projection_horizon': 5,\r\n                  'static_mode': 'concatenate',\r\n                  'time_mode': 'concatenate'}\r\ntreatment_model = treatment_effects_model(model_name, model_parameters, task='classification')\r\ntreatment_model.fit(dataset_training)\r\n    \r\n\r\n# Return the factual predictions on the testing set\r\ntest_y_hat = treatment_model.predict(dataset_testing)\r\n\r\nprint('Finish treatment effects model training and testing.')\r\n\r\nfrom evaluation import Metrics\r\nfrom evaluation import print_performance\r\n\r\n# Evaluate predictor model\r\nresult = Metrics(metric_sets, metric_parameters).evaluate(dataset_testing.label, test_y_hat)\r\nprint('Finish predictor model evaluation.')\r\n\r\nprint('Overall performance')\r\nprint_performance(result, metric_sets, metric_parameters)
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Clairvoyance crn/MM.py b/Clairvoyance crn/MM.py
--- a/Clairvoyance crn/MM.py	(revision a0ed8904217e5aaf71807523b5c4e2590cff11ca)
+++ b/Clairvoyance crn/MM.py	(date 1650713975188)
@@ -19,8 +19,8 @@
 
 
 # write alll print output to program output file
-file_path = 'program output.txt'
-sys.stdout = open(file_path, "w")
+#file_path = 'program output.txt'
+#sys.stdout = open(file_path, "w")
 
 # IN THE NEXT PART LOAD THE DATA SET AND FORMAT IT AS NEEDED
 
Index: gammaprocesssimulation/covariateSeries.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#%%\r\nfrom cmath import e, exp\r\nfrom this import d\r\nfrom turtle import fd\r\nfrom typing_extensions import Self\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\n\r\n#generate covariance matrix to indicate relationship between covariates \r\n\r\nclass CovariateGenerator:\r\n\r\n    def __init__(self,processArguments,generationArguments):\r\n        # general process parameters\r\n        self.timeFrame = processArguments[0]\r\n        self.steps = processArguments[1]\r\n        self.stepsize = self.timeFrame/self.steps\r\n\r\n        # parameters for exogenous variable generation\r\n        self.mean = generationArguments[0]\r\n        self.standarddev = generationArguments[1]\r\n\r\n        self.covariance = self.__generateCovarianceMatrix()\r\n\r\n\r\n    def __generateCovarianceMatrix(self):\r\n    \r\n        correlationMatrix = np.empty((len(self.standarddev),len(self.standarddev)))\r\n        # generate standardized data i.e. correlation matrix and scale with standard deviations\r\n        # no guarantee that it is positive definite! must be changed\r\n        X = 0\r\n        while X < len(self.standarddev):\r\n         Y = 0\r\n         while Y <= X:\r\n            correlationMatrix[X][Y] = np.random.uniform(-0.5,0.5)\r\n            correlationMatrix[Y][X] = correlationMatrix[X][Y]\r\n            Y+=1\r\n         X+=1\r\n    \r\n        standarddevMatrix = np.diag(self.standarddev)\r\n        covariance = np.matmul(standarddevMatrix,np.matmul(correlationMatrix,standarddevMatrix))\r\n        return covariance\r\n    \r\n    def generateCovariateTimePoint(self):\r\n        \r\n        # should we add bias here?\r\n        covariates =  list(np.random.multivariate_normal(self.mean,self.covariance))\r\n        \r\n        return covariates\r\n    \r\n        # following combination ensures symmetry of the matrix,\r\n        #return 0.5*(covariance + covariance.transpose()) as in paper bica \r\n    \r\n    def generateCovariateTimeSeries(self):\r\n        covariateTimeSeries = list()\r\n\r\n       \r\n        for step in range(self.steps):\r\n            covariates = self.generateCovariateTimePoint()\r\n            covariateTimeSeries.append(covariates)\r\n            \r\n            \r\n        return covariateTimeSeries\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n'''\r\nx, y = np.random.multivariate_normal([covariateGenerationArguments.get(\"temperature\")[0],covariateGenerationArguments.get(\"temperature\")[1]], covarianceMatrix, 5000)\r\nplt.plot(x, y, 'x')\r\nplt.axis('equal')\r\nplt.show()\r\n'''\r\n# generate covariates based on the chosen mean and covariance matrix\r\n# these covariates are not related to eachother in time!\r\n\r\n\r\n\r\n\r\n\r\n'''\r\n# momentarily no immediate relationship between covariates at differing time points\r\n\r\n\r\ndef generateSampleTimeSeries(generationArgs,covarianceMatrix,steps,samplesize):\r\n    sample = []\r\n    for case in range(samplesize):\r\n        sample.extend(generateAttributeTimeSeries(case,generationArgs,covarianceMatrix,steps))\r\n\r\n    return sample\r\n\r\n\r\n\r\n# generate treatment vector given the observed characteristics using bernouli choice with sigmoid probability\r\n\r\n\r\n\r\n\r\n\r\n'''\r\n\r\n\r\n\r\n#%%\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n'''\r\n\r\nclass MaintenanceActions(Enum):\r\n\r\n    upkeep = 1\r\n    repair = 2\r\n    overhaul = 3\r\n\r\nclass maintenance:\r\n    \r\n    criteria = []\r\n\r\n    def __calculateCondition(condition,mean,stddev):\r\n        \r\n        newCondition = condition + np.random.normal(mean,stddev)\r\n        return newCondition\r\n    \r\n    def __measureCondition(condition):\r\n       return condition + np.random.normal(0,5)\r\n\r\n    def maintenancePolicy(self,condition, covariates):\r\n        if(self.__measureCondition(condition) + np.dot(self.criteria,covariates) < 20):\r\n            return MaintenanceActions.upkeep\r\n        if(self.__measureCondition(condition) + np.dot(self.criteria,covariates) < 20):\r\n            return MaintenanceActions.repair\r\n        if(self.__measureCondition(condition) + np.dot(self.criteria,covariates) < 20):\r\n            return MaintenanceActions.overhaul\r\n       \r\n    \r\n    \r\n    def doMaintenance(self,condition,covariates):\r\n        \r\n        policy = self.maintenancePolicy(self,condition,covariates)\r\n\r\n        if(policy == MaintenanceActions.upkeep):\r\n            self.__calculateCondition(condition,10,5)\r\n            print(\"Upkeep Performed\")\r\n       \r\n        elif(policy == MaintenanceActions.repair):\r\n           \r\n            self.__calculateCondition(condition,30,15)\r\n            print(\"Repair Performed\")\r\n       \r\n        elif(policy == MaintenanceActions.overhaul):\r\n            self.__calculateCondition(condition,100,5)\r\n            print(\"Overhaul Performed\")\r\n            \r\n            \r\n'''
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/gammaprocesssimulation/covariateSeries.py b/gammaprocesssimulation/covariateSeries.py
--- a/gammaprocesssimulation/covariateSeries.py	(revision a0ed8904217e5aaf71807523b5c4e2590cff11ca)
+++ b/gammaprocesssimulation/covariateSeries.py	(date 1650987744698)
@@ -16,7 +16,7 @@
         # general process parameters
         self.timeFrame = processArguments[0]
         self.steps = processArguments[1]
-        self.stepsize = self.timeFrame/self.steps
+        self.stepsize = self.timeFrame/self.steps #averageduration
 
         # parameters for exogenous variable generation
         self.mean = generationArguments[0]
Index: gammaprocesssimulation/gammaProcess.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+> \r\nfrom cmath import e, exp\r\nimport numpy as np\r\nfrom maintenance import MaintenanceProgram\r\nfrom array import *\r\n\r\n\r\n\r\nclass Deteriorationprocess:\r\n\r\n    def __init__(self, processArguments, machine, covariateGenerator ,maintenanceProgram):\r\n       \r\n        # define basic process properties\r\n        self.timeFrame = processArguments[0]\r\n        self.steps = processArguments[1]\r\n        self.scaleParameter = processArguments[2]\r\n        self.stepsize = self.timeFrame/self.steps\r\n        \r\n        # define machine and it's properties tied to the process\r\n        \r\n        self.machine =  machine\r\n        self.covariateGenerator = covariateGenerator\r\n        self.maintenance = maintenanceProgram\r\n\r\n    # increment the machinetime\r\n    def scaledTimeIncrement(self,covariates,Betas):\r\n        return (e**(np.dot(Betas,covariates)))*self.stepsize\r\n    \r\n     \r\n    # creating equivalent to \"z\"-values for gamma distribution!                                                                                                                 \r\n    def shapeFunction(self,newMachineTime,oldMachineTime):\r\n        return (self.machine.meanDegradation(newMachineTime) - self.machine.meanDegradation(oldMachineTime))/ self.machine.sigma**2\r\n   \r\n    def generaterun(self):\r\n        \r\n        dataList = list()\r\n        oldMachineTime = 0\r\n        prevGammaState= float(self.machine.initialCondition)\r\n        prevDegradation = prevGammaState* self.machine.sigma**2\r\n        \r\n       \r\n        \r\n        \r\n\r\n\r\n        for step in range(self.steps):\r\n             \r\n             \r\n\r\n             # generate covariates at for current step\r\n             covariates = self.covariateGenerator.generateCovariateTimePoint()\r\n             \r\n             # increment machineTime according to theory of accumulation of damages\r\n             newMachineTime = oldMachineTime + self.scaledTimeIncrement(covariates, self.machine.betas)\r\n             \r\n             # determine shape parameter of gamma jump!\r\n             shape = self.shapeFunction(newMachineTime,oldMachineTime)\r\n             \r\n             # jump the deterioration state!\r\n             incrementDeterioriation = np.random.gamma(shape, self.scaleParameter)\r\n             print(type(prevGammaState))\r\n             print(type(incrementDeterioriation))\r\n             print(step)\r\n             currentGammaState = prevGammaState + incrementDeterioriation\r\n             currentDegradation = currentGammaState * self.machine.sigma**2\r\n             \r\n             # calculate sensor output as proxy for condition\r\n             sensordata = np.random.normal(currentDegradation,10)\r\n             \r\n             # calculate Production for the period given current condition\r\n\r\n             production = (self.machine.criticalDamage - (currentDegradation + prevDegradation)/2)*self.machine.maxProductionSpeed*self.stepsize*self.maintenance.calculateTreatementCost()\r\n\r\n             treatmentDecision = self.maintenance.generateTreatmentDecision(covariates)\r\n                    \r\n             if(treatmentDecision):\r\n              newMachineTime,currentGammaState = self.maintenance.performTreatment(newMachineTime,currentGammaState)\r\n             \r\n             \r\n             timestepData = [step, covariates[0],covariates[1],covariates[2],sensordata,currentDegradation,production,treatmentDecision]\r\n             dataList.append(timestepData)\r\n\r\n             # check if machine has failed?\r\n\r\n             failedstate = self.machine.failed(currentDegradation)\r\n             \r\n             if(failedstate == True):\r\n                self.machine.condition = np.nan\r\n                continue\r\n             \r\n             # set current values to old values for next iteration\r\n             \r\n             oldMachineTime = newMachineTime\r\n             prevGammaState = currentGammaState\r\n             prevDegradation = prevGammaState*self.machine.sigma**2\r\n         \r\n\r\n        return dataList\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n# m(t) in paper, determines normal degradation profile i.e. the amount of shocks in 1 jump/ timesteps.\r\n# The scale parameter is left as default 1\r\n\r\n\r\n# under assumption that covariates remain constant until next measurement:\r\n\r\n  \r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/gammaprocesssimulation/gammaProcess.py b/gammaprocesssimulation/gammaProcess.py
--- a/gammaprocesssimulation/gammaProcess.py	(revision a0ed8904217e5aaf71807523b5c4e2590cff11ca)
+++ b/gammaprocesssimulation/gammaProcess.py	(date 1650988157427)
@@ -37,16 +37,8 @@
         oldMachineTime = 0
         prevGammaState= float(self.machine.initialCondition)
         prevDegradation = prevGammaState* self.machine.sigma**2
-        
-       
-        
-        
 
-
-        for step in range(self.steps):
-             
-             
-
+        for step in range(self.steps): #nog eens 10 keer
              # generate covariates at for current step
              covariates = self.covariateGenerator.generateCovariateTimePoint()
              
@@ -86,7 +78,7 @@
              
              if(failedstate == True):
                 self.machine.condition = np.nan
-                continue
+                continue #break?
              
              # set current values to old values for next iteration
              
Index: Clairvoyance crn/treatments/CRN/data_utils.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import numpy as np\r\n\r\nfrom utils.data_utils import concate_xs, concate_xt\r\n\r\n\r\ndef data_preprocess_counterfactuals(\r\n    encoder_model, dataset, patient_id, timestep, treatment_options, fold, split, static_mode, time_mode\r\n):\r\n    \"\"\"Preprocess the dataset for obtaining counterfactual predictions for sequences of future treatments.\r\n\r\n    Args:\r\n        - encoder_model: trained encoder model for initializing decoder\r\n        - dataset: temporal, static, label, time, treatment information\r\n        - patient_id: patient id of patient for which the counterfactuals are computed\r\n        - timestep: timestep in the patient trajectory where counterfactuals are predicted\r\n        - treatment_options: treatment options for computing the counterfactual trajectories\r\n        - fold: test fold\r\n        - test_split: testing set splitting parameter\r\n        - static_mode: 'concatenate' or None\r\n        - time_mode: 'concatenate' or None\r\n\r\n    Returns:\r\n        - patient_history: history of patient outcome until the specified timestep\r\n        - encoder_output: patient output for the first treatment in the treatment options; this one-step-ahead prediction\r\n            is made using the encoder model.\r\n        - dataset_crn_decoder: dataset that can be used to obtain the counterfactual predictions from the decoder model.\r\n    \"\"\"\r\n    x, s, y, t, treat = dataset.get_fold(fold, split)\r\n\r\n    max_sequence_length = x.shape[1]\r\n    num_treatment_options = treatment_options.shape[0]\r\n    projection_horizon = treatment_options.shape[1] - 1\r\n\r\n    if static_mode == \"concatenate\":\r\n        x = concate_xs(x, s)\r\n\r\n    if time_mode == \"concatenate\":\r\n        x = concate_xt(x, t)\r\n\r\n    x = np.repeat([x[patient_id]], num_treatment_options, axis=0)\r\n    y = np.repeat([y[patient_id]], num_treatment_options, axis=0)\r\n\r\n    treat = np.repeat([treat[patient_id][: timestep - 1]], num_treatment_options, axis=0)\r\n    treat = np.concatenate([treat, treatment_options], axis=1)\r\n\r\n    dataset_crn_encoder = dict()\r\n\r\n    one_hot_treatments = np.zeros(shape=(treat.shape[0], treat.shape[1], 2))\r\n    treat = np.round(treat)\r\n    for patient_id in range(treat.shape[0]):\r\n        for t in range(treat.shape[1]):\r\n            if treat[patient_id][t][0] == 0.0:\r\n                one_hot_treatments[patient_id][t] = [1, 0]\r\n            elif treat[patient_id][t][0] == 1.0:\r\n                one_hot_treatments[patient_id][t] = [0, 1]\r\n            elif treat[patient_id][t][0] == -1.0:\r\n                one_hot_treatments[patient_id][t] = [-1, -1]\r\n\r\n    one_hot_treatments_encoder = one_hot_treatments[:, :timestep, :]\r\n    one_hot_treatments_encoder = np.concatenate(\r\n        [\r\n            one_hot_treatments_encoder,\r\n            np.zeros(shape=(one_hot_treatments.shape[0], max_sequence_length - timestep, one_hot_treatments.shape[-1])),\r\n        ],\r\n        axis=1,\r\n    )\r\n\r\n    dataset_crn_encoder[\"current_covariates\"] = x\r\n    dataset_crn_encoder[\"current_treatments\"] = one_hot_treatments_encoder\r\n    dataset_crn_encoder[\"previous_treatments\"] = one_hot_treatments_encoder[:, :-1, :]\r\n    dataset_crn_encoder[\"active_entries\"] = np.ones(shape=(x.shape[0], x.shape[1], 1))\r\n    dataset_crn_encoder[\"sequence_lengths\"] = timestep * np.ones(shape=(num_treatment_options))\r\n\r\n    test_br_states = encoder_model.get_balancing_reps(dataset_crn_encoder)\r\n    test_encoder_predictions = encoder_model.get_predictions(dataset_crn_encoder)\r\n\r\n    dataset_crn_decoder = dict()\r\n    dataset_crn_decoder[\"init_states\"] = test_br_states[:, timestep - 1, :]\r\n    dataset_crn_decoder[\"encoder_output\"] = test_encoder_predictions[:, timestep - 1, :]\r\n    dataset_crn_decoder[\"current_treatments\"] = one_hot_treatments[:, timestep : timestep + projection_horizon, :]\r\n    dataset_crn_decoder[\"previous_treatments\"] = one_hot_treatments[\r\n        :, timestep - 1 : timestep + projection_horizon - 1, :\r\n    ]\r\n    dataset_crn_decoder[\"active_entries\"] = np.ones(shape=(one_hot_treatments.shape[0], one_hot_treatments.shape[1], 1))\r\n    dataset_crn_decoder[\"sequence_lengths\"] = timestep * np.ones(shape=(projection_horizon))\r\n\r\n    patient_history = y[0][:timestep]\r\n    encoder_output = test_encoder_predictions[:, timestep - 1 : timestep, :]\r\n\r\n    return patient_history, encoder_output, dataset_crn_decoder\r\n\r\n\r\ndef data_preprocess(dataset, fold, split, static_mode, time_mode):\r\n    \"\"\"Preprocess the dataset.\r\n\r\n    Args:\r\n        - dataset: temporal, static, label, time, treatment information\r\n        - fold: Cross validation fold\r\n        - split: 'train', 'valid' or 'test'\r\n        - static_mode: 'concatenate' or None\r\n        - time_mode: 'concatenate' or None\r\n\r\n    Returns:\r\n        - dataset_crn: dataset dictionary for training the CRN.\r\n    \"\"\"\r\n    x, s, y, t, treat = dataset.get_fold(fold, split)\r\n\r\n    if static_mode == \"concatenate\":\r\n        x = concate_xs(x, s)\r\n\r\n    if time_mode == \"concatenate\":\r\n        x = concate_xt(x, t)\r\n\r\n    dataset_crn = dict()\r\n\r\n    one_hot_treatments = np.zeros(shape=(treat.shape[0], treat.shape[1], 2))\r\n    treat = np.round(treat)\r\n    for patient_id in range(treat.shape[0]):\r\n        for timestep in range(treat.shape[1]):\r\n            if treat[patient_id][timestep][0] == 0.0:\r\n                one_hot_treatments[patient_id][timestep] = [1, 0]\r\n            elif treat[patient_id][timestep][0] == 1.0:\r\n                one_hot_treatments[patient_id][timestep] = [0, 1]\r\n            elif treat[patient_id][timestep][0] == -1.0:\r\n                one_hot_treatments[patient_id][timestep] = [-1, -1]\r\n\r\n    active_entries = np.ndarray.max((y >= 0).astype(float), axis=-1)\r\n    sequence_lengths = np.sum(active_entries, axis=1).astype(int)\r\n    active_entries = active_entries[:, :, np.newaxis]\r\n\r\n    dataset_crn[\"current_covariates\"] = x\r\n    dataset_crn[\"current_treatments\"] = one_hot_treatments\r\n    dataset_crn[\"previous_treatments\"] = one_hot_treatments[:, :-1, :]\r\n    dataset_crn[\"outputs\"] = y\r\n    dataset_crn[\"active_entries\"] = active_entries\r\n    dataset_crn[\"sequence_lengths\"] = sequence_lengths\r\n\r\n    return dataset_crn\r\n\r\n\r\ndef process_seq_data(dataset, states, projection_horizon):\r\n    \"\"\"Split the sequences in the training data to train the decoder.\r\n\r\n    Args:\r\n        - dataset: dataset with training data sequences\r\n        - states: encoder states used to initialize the decoder\r\n        - projection_horizon: number of future timesteps for training decoder\r\n\r\n    Returns:\r\n        - dataset for training decoder\r\n    \"\"\"\r\n\r\n    outputs = dataset[\"outputs\"]\r\n    sequence_lengths = dataset[\"sequence_lengths\"]\r\n    active_entries = dataset[\"active_entries\"]\r\n    current_treatments = dataset[\"current_treatments\"]\r\n    previous_treatments = dataset[\"previous_treatments\"]\r\n\r\n    num_patients, num_time_steps, num_features = outputs.shape\r\n\r\n    num_seq2seq_rows = num_patients * num_time_steps\r\n\r\n    seq2seq_state_inits = np.zeros((num_seq2seq_rows, states.shape[-1]))\r\n    seq2seq_previous_treatments = np.zeros((num_seq2seq_rows, projection_horizon, previous_treatments.shape[-1]))\r\n    seq2seq_current_treatments = np.zeros((num_seq2seq_rows, projection_horizon, current_treatments.shape[-1]))\r\n    seq2seq_current_covariates = np.zeros((num_seq2seq_rows, projection_horizon, outputs.shape[-1]))\r\n    seq2seq_outputs = np.zeros((num_seq2seq_rows, projection_horizon, outputs.shape[-1]))\r\n    seq2seq_active_entries = np.zeros((num_seq2seq_rows, projection_horizon, active_entries.shape[-1]))\r\n    seq2seq_sequence_lengths = np.zeros(num_seq2seq_rows)\r\n\r\n    total_seq2seq_rows = 0  # we use this to shorten any trajectories later\r\n\r\n    for i in range(num_patients):\r\n\r\n        sequence_length = int(sequence_lengths[i])\r\n\r\n        for t in range(1, sequence_length):  # shift outputs back by 1\r\n            seq2seq_state_inits[total_seq2seq_rows, :] = states[i, t - 1, :]  # previous state output\r\n\r\n            max_projection = min(projection_horizon, sequence_length - t)\r\n\r\n            seq2seq_active_entries[total_seq2seq_rows, :max_projection, :] = active_entries[\r\n                i, t : t + max_projection, :\r\n            ]\r\n            seq2seq_previous_treatments[total_seq2seq_rows, :max_projection, :] = previous_treatments[\r\n                i, t - 1 : t + max_projection - 1, :\r\n            ]\r\n            seq2seq_current_treatments[total_seq2seq_rows, :max_projection, :] = current_treatments[\r\n                i, t : t + max_projection, :\r\n            ]\r\n            seq2seq_outputs[total_seq2seq_rows, :max_projection, :] = outputs[i, t : t + max_projection, :]\r\n            seq2seq_sequence_lengths[total_seq2seq_rows] = max_projection\r\n            seq2seq_current_covariates[total_seq2seq_rows, :max_projection, :] = outputs[\r\n                i, t - 1 : t + max_projection - 1, :\r\n            ]\r\n\r\n            total_seq2seq_rows += 1\r\n\r\n    # Filter everything shorter\r\n    seq2seq_state_inits = seq2seq_state_inits[:total_seq2seq_rows, :]\r\n    seq2seq_previous_treatments = seq2seq_previous_treatments[:total_seq2seq_rows, :, :]\r\n    seq2seq_current_treatments = seq2seq_current_treatments[:total_seq2seq_rows, :, :]\r\n    seq2seq_current_covariates = seq2seq_current_covariates[:total_seq2seq_rows, :, :]\r\n    seq2seq_outputs = seq2seq_outputs[:total_seq2seq_rows, :, :]\r\n    seq2seq_active_entries = seq2seq_active_entries[:total_seq2seq_rows, :, :]\r\n    seq2seq_sequence_lengths = seq2seq_sequence_lengths[:total_seq2seq_rows]\r\n\r\n    # Package outputs\r\n    seq2seq_data_map = {\r\n        \"init_state\": seq2seq_state_inits,\r\n        \"previous_treatments\": seq2seq_previous_treatments,\r\n        \"current_treatments\": seq2seq_current_treatments,\r\n        \"current_covariates\": seq2seq_current_covariates,\r\n        \"outputs\": seq2seq_outputs,\r\n        \"sequence_lengths\": seq2seq_sequence_lengths,\r\n        \"active_entries\": seq2seq_active_entries,\r\n    }\r\n\r\n    return seq2seq_data_map\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Clairvoyance crn/treatments/CRN/data_utils.py b/Clairvoyance crn/treatments/CRN/data_utils.py
--- a/Clairvoyance crn/treatments/CRN/data_utils.py	(revision a0ed8904217e5aaf71807523b5c4e2590cff11ca)
+++ b/Clairvoyance crn/treatments/CRN/data_utils.py	(date 1650713975204)
@@ -105,6 +105,8 @@
     """
     x, s, y, t, treat = dataset.get_fold(fold, split)
 
+    print(s)
+
     if static_mode == "concatenate":
         x = concate_xs(x, s)
 
